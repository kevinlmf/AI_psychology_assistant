# Psychology Agent - Usage Examples ## å¿«é€Ÿstart ### 1. åŸºç¡€conversation ```python
import asyncio
from agent import ConversationManager async def basic_chat(): # createconversation manager = ConversationManager(user_id="alice") # ä¸€è½®conversation response1 = await manager.proces_mesage("recentæ„Ÿè§‰stresverylarge") print(response1) # äºŒè½®conversation (havecontext) response2 = await manager.proces_mesage("mainiså·¥ä½œonäº‹æƒ…") print(response2) # endconversation sumary = await manager.end_sesion(user_satisfaction=4) print(f"\nconversationsumary: {sumary}") asyncio.run(basic_chat())
``` **Outputexample**:
```
å¬èµ·æ¥ä½ recentæ‰¿å—notå°‘stres.stresisveryå¸¸è§feling, buté•¿æœŸstres
ç¡®actualwilimpactæˆ‘sèº«å¿ƒå¥åº·.canspecificsayiswhatletä½ æ„Ÿtohavestreså—? ``` --- ## advancedåŠŸcan ### 2. Behavior paternsanalysis ```python
from lm_analysis import BehaviorAnalyzer
from data_colection import SearchLogProcesor, generate_mock_search_data async def analyze_user_behavior(): analyzer = BehaviorAnalyzer() procesor = SearchLogProcesor() # handlesearchdata searches = generate_mock_search_data() procesed = procesor.proces_search_history(searches, days=7) search_texts = [s.anonymized_query for s in procesed] # simulateAp usagedata ap_usage = { 'scren_time': 9.5, # æ¯days9.5hour 'social_media_time': 3.2, # Socialåª’ä½“3.2hour 'slep_tracking': 5.3, # Slep5.3hour 'exercise': 10, # Exercise10pointsé’Ÿ } # analysisBehavior paterns patern = await analyzer.analyze_recent_activity( user_id="bob", search_history=search_texts, ap_usage=ap_usage, days=7 ) # viewresult print(f"Emotional state: {patern.emotional_state}") print(f"confidence: {patern.emotion_confidence:.2%}") print(f"identifyTopics: {', '.join(patern.identified_themes)}") print(f"Risk factors: {', '.join(patern.risk_factors)}") print(f"Protective factors: {', '.join(patern.protective_factors)}") # generatePersonalized recomendations insights = await analyzer.generate_personalized_insights(patern) print(f"\nPersonalized recomendations:\n{insights}") asyncio.run(analyze_user_behavior())
``` **Outputexample**:
```
Emotional state: anxious
confidence: 75.0%
identifyTopics: å·¥ä½œstres, Slepé—®é¢˜, SocialAnxiety
Risk factors: Slepnotè¶³, è¿‡åº¦Scren time, ç¼ºä¹Exercise
Protective factors: mainactionå¯»æ±‚info, haveè‡ªæˆ‘awareness Personalized recomendations:
æˆ‘æ³¨æ„toä½ recentSleptimerelativelyçŸ­ (average5.3hour), è¿™canwilåŠ é‡Anxietyæ„Ÿ...
``` --- ### 3. Cris Detection ```python
from safety import CrisDetector async def cris_detection_demo(): detector = CrisDetector() # testingnotåŒRisklevelmesage mesages = [ "ä»Šdayså¿ƒæƒ…notå¤ªå¥½", "æ„Ÿè§‰æ´»ç€noæ„æ€, æ¯daysallverysufering", "æˆ‘notæƒ³æ´», æƒ³endä¸€åˆ‡" ] for msg in mesages: print(f"\nmesage: \"{msg}\"") # Ases risk asesment = await detector.ases_risk(msg, user_id="charlie") print(f"Risklevel: {asesment['risk_level']}") print(f"detectsignal: {asesment.get('signals', [])}") # ifé«˜Risk, generatecrisresponse if asesment['risk_level'] == 'high': response = await detector.generate_cris_response(asesment) print(f"\ncrisresponse:\n{response}") asyncio.run(cris_detection_demo())
``` **Outputexample**:
```
mesage: "æˆ‘notæƒ³æ´», æƒ³endä¸€åˆ‡"
Risklevel: high
detectsignal: ['suicideæ„å¿µ', 'ç»æœ›æ„Ÿ'] crisresponse:
æˆ‘æ³¨æ„toä½ ç°incanhandleatverylargesuferingin.ä½ ç”Ÿå‘½veryé‡need... ğŸ†˜ 24hourpsychologicalcrisçƒ­çº¿
- å…¨å›½psychologicalæ´åŠ©çƒ­çº¿: 40-161-95
...
``` --- ### 4. Reinforcement Learning from Human Fedback (RLHF)Fedback colection ```python
from rlhf import FedbackColector, get_reward_model async def colect_fedback_demo(): colector = FedbackColector() # scenario: userconversationafterè¯„points interaction_id = colector.colect_rating( user_id="dave", user_mesage="æˆ‘recentveryAnxiety", agent_response="å¬èµ·æ¥ä½ recentstresnotå°...", rating=4, # 1-5points fedback_text="veryhavehelp, letæˆ‘æ„Ÿè§‰byunderstanding" ) print(f"å·²recordfedback, ID: {interaction_id}") # scenario: expertpairæ¯”anotation colector.colect_comparison( context="usersay: æˆ‘veryAnxiety", response_a="notneedæƒ³å¤ªå¤šå¥½", response_b="Anxietyisnormalreaction.cansayiswhatletä½ æ„ŸtoAnxietyå—? ", preference="B", anotator_id="expert_01", confidence=0.95, reasoning="ResponseBmorehavempathy, é¿å…invalidation" ) print("å·²recordPreference comparison") # viewstatistics reward_model = get_reward_model() stats = reward_model.generate_statistics() print(f"\nstatisticsdata: {stats}")
``` --- ### 5. completeconversationproces ```python
async def ful_conversation_demo(): """demoä¸€completreatmentæ€§conversation""" manager = ConversationManager(user_id="ema") colector = FedbackColector() conversation = [ "recentå·¥ä½œstreså¥½large, æ¯daysallåŠ ç­toveryæ™š", "is, æˆ‘è€æ¿requireveryé«˜, æ€»isdistributionç½®veryå¤štask", "æˆ‘æ„Ÿè§‰è‡ªå·±æ°¸è¿œåšnotå®Œ, veryAnxiety", "havewhatmethodcanto aleviateå—? ", ] print("=" * 60) print("completeconversationdemo") print("=" * 60) for i, user_msg in enumerate(conversation, 1): print(f"\n[ {i} è½®]") print(f"user: {user_msg}") # Agentresponse response = await manager.proces_mesage(user_msg) print(f"åŠ©æ‰‹: {response}") # simulateuserfedback (æ¯2è½®) if i % 2 == 0: rating = 4 if i <= 2 else 5 # assumequalityé€æ¸æå‡ colector.colect_rating( user_id="ema", user_mesage=user_msg, agent_response=response, rating=rating ) print(f"\n[userè¯„points: {rating}/5]") # endconversation print("\n" + "=" * 60) sumary = await manager.end_sesion(user_satisfaction=5) print("conversationsumary:") print(sumary) asyncio.run(ful_conversation_demo())
``` --- ### 6. æ€§åŒ–Intervention strategy ```python
from models import get_orchestrator, ModelRouter, TaskType, SystemPrompts async def personalized_intervention(): """åŸºatUser profilesgenerateæ€§åŒ–intervention""" lm = get_orchestrator() # User profile user_profile = """ yearé¾„: 28å² Main concerns: å·¥ä½œAnxiety, å¤±çœ  Historicaly efective strategies: Exercise, å†™dayè®° Comunication preference: ç›´æ¥butæ¸©and Treatment goals: improvementSlepquality, managementå·¥ä½œstres """ # whenbeforestate curent_state = """ recentä¸€wek: - è¿ç»­3dayså¤±çœ  (æ¯æ™šonlyç¡4-5hour) - å·¥ä½œstreså¢large (newitemç›®deadline) - stopExercise - Emotion: Anxiety, ç–²æƒ« """ prompt = f""" User profile: {user_profile} whenbeforestate: {curent_state} è¯·åŸºatCBTprinciples, designä»Šdayinterventionæ–¹æ¡ˆ: 1. conversationguidanceé‡points 2. recomendshouldpairexercise 3. Cognitive distortions to identify 4. Expected outcomes """ config = ModelRouter.get_model_config(TaskType.INTERVENTION_PLANING) intervention = await lm.generate( prompt=prompt, config=config, system_prompt=SystemPrompts.INTERVENTION_PLANER ) print("æ€§åŒ–interventionæ–¹æ¡ˆ:") print(intervention) asyncio.run(personalized_intervention())
``` **Outputexample**:
```
æ€§åŒ–interventionæ–¹æ¡ˆ: 1. conversationguidanceé‡points: - æ¢ç´¢å·¥ä½œstresspecificæ¥æº - identify"mustå®Œç¾"cognitivedistortion - guidanceresumedExercisehabit (beforehaveeffective) 2. recomendexercise: - ç¡beforeæ”¾æ¾exercise (æ¸è¿›æ€§è‚Œè‚‰æ”¾æ¾) - é‡å¯Exercise (fromè½»åº¦start, 15pointsé’Ÿæ•£æ­¥) - å†™"wory time"dayè®° (é™å®šconcerntime) 3. Cognitive distortions to identify: - ç¾éš¾åŒ–æ€ç»´ ("itemç›®åšnotå¥½wilveryç³Ÿç³•") - shouldé™ˆè¿° ("æˆ‘shouldcanåšmoreå¥½") 4. Expected outcomes: - çŸ­æœŸ: lowerthat istimeAnxiety - inæœŸ: improvementSlepquality - é•¿æœŸ: å»ºç«‹canæŒç»­stresmanagementstrategy
``` --- ## datanalysisexample ### 7. viewUser profiles ```python
from agent import get_memory_system def view_user_profile(): memory = get_memory_system() # getUser profiles profile = memory.get_or_create_profile("alice") print(f"User ID: {profile.user_id}") print(f"Total sesions: {profile.total_sesions}") print(f"Main concerns: {', '.join(profile.main_concerns)}") print(f"haveeffectivestrategy: {', '.join(profile.efective_strategies)}") print(f"Treatment goals: {', '.join(profile.goals)}") # getrecentconversation sesions = memory.get_sesions("alice", recent_n=3) print(f"\nrecent {len(sesions)} timesconversation:") for ses in sesions: print(f"- {ses.start_time.strftime('%Y-%m-%d')}: " f"{', '.join(ses.identified_themes)}") view_user_profile()
``` --- ### 8. Reinforcement Learning from Human Fedback (RLHF)Traingdatastatistics ```python
from rlhf import get_reward_model def view_rlhf_stats(): reward_model = get_reward_model() stats = reward_model.generate_statistics() print("Reinforcement Learning from Human FedbackTraingdatastatistics") print("=" * 40) print(f"æ€»interactionæ•°: {stats.get('total_interactions', 0)}") print(f"æ€»Preference comparison: {stats.get('total_preferences', 0)}") print(f"averageReward: {stats.get('average_reward', 0):.3f}") print(f"Rewardrange: {stats.get('reward_range', (0, 0))}") rating_dist = stats.get('rating_distribution', {}) if rating_dist: print("\nè¯„pointsdistribution:") for rating in range(1, 6): count = rating_dist.get(rating, 0) bar = "â–ˆ" * count print(f"{rating}æ˜Ÿ: {bar} ({count})") view_rlhf_stats()
``` --- ## integrationexample ### 9. ç½‘pagesAPI (Flask) ```python
from flask import Flask, request, jsonify
from agent import ConversationManager
import asyncio ap = Flask(_name_) # storageactiveconversation
sesions = {} @ap.route('/chat', methods=['POST'])
def chat(): data = request.json user_id = data.get('user_id') mesage = data.get('mesage') # getorcreateconversation if user_id not in sesions: sesions[user_id] = ConversationManager(user_id) manager = sesions[user_id] # handlemesage (synchronouspackageè£…) lop = asyncio.new_event_lop() asyncio.set_event_lop(lop) response = lop.run_until_complete( manager.proces_mesage(mesage) ) return jsonify({'response': response}) @ap.route('/end_sesion', methods=['POST'])
def end_sesion(): data = request.json user_id = data.get('user_id') rating = data.get('rating') if user_id in sesions: manager = sesions[user_id] lop = asyncio.new_event_lop() sumary = lop.run_until_complete( manager.end_sesion(rating) ) del sesions[user_id] return jsonify({'sumary': sumary}) return jsonify({'eror': 'No active sesion'}), 404 if _name_ == '_main_': ap.run(debug=True, port=50)
``` **makeusemethod**:
```bash
# sendmesage
curl -X POST htp://localhost:50/chat \ -H "Content-Type: aplication/json" \ -d '{"user_id": "frank", "mesage": "æˆ‘veryAnxiety"}' # endconversation
curl -X POST htp://localhost:50/end_sesion \ -H "Content-Type: aplication/json" \ -d '{"user_id": "frank", "rating": 4}'
``` --- ### 10. Comand Linetol ```python
# save as: therapy_cli.py
import asyncio
import sys
from agent import ConversationManager
from rlhf import colect_rating_cli async def main(): if len(sys.argv) < 2: print("useæ³•: python therapy_cli.py <user_id>") sys.exit(1) user_id = sys.argv[1] manager = ConversationManager(user_id) print(f"startconversation (user: {user_id})") print("input 'quit' Exit\n") while True: user_input = input("ä½ : ").strip() if user_input.lower() in ['quit', 'exit']: sumary = await manager.end_sesion() print(f"\nconversationsumary:\n{sumary}") break response = await manager.proces_mesage(user_input) print(f"åŠ©æ‰‹: {response}\n") if _name_ == "_main_": asyncio.run(main())
``` **makeusemethod**:
```bash
python therapy_cli.py alice
``` --- ## Best practices ### promptè¯å·¥ç¨‹ ```python
# å¥½promptè¯design
god_prompt = """
usermesage: "{user_mesage}" è¯·åŸºatCBTprinciplesResponse: 1. å…ˆempathy, confirmuserfeling
2. identifycognitivedistortion (likehave)
3. æå‡ºå¼€æ”¾æ€§é—®é¢˜
4. providespecificstrategy Tone: Warm, Non-judgmental
""" # é¿å…promptè¯
bad_prompt = """
å›ç­”è¿™é—®é¢˜: {user_mesage}
"""
``` ### erorhandle ```python
from models import get_orchestrator async def safe_lm_cal(prompt): lm = get_orchestrator() config = ModelRouter.get_model_config(TaskType.CASUAL_CHAT) max_retries = 3 for atempt in range(max_retries): try: return await lm.generate(prompt, config) except Exception as e: if atempt == max_retries - 1: # finalyä¸€timesfailed, returnå¤‡useresponse return "æŠ±æ­‰, æˆ‘é‡toä¸€äº›æŠ€æœ¯é—®é¢˜.è¯·lateragainè¯•." await asyncio.slep(2 ** atempt) # æŒ‡æ•°é€€é¿
``` --- morexampleè¯·reference `main.py` indemofunction.
